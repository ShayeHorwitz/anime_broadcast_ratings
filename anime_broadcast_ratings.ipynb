{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anime News Network \"Japanese Animation TV Ranking\" scraping project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Every week, the Japanese company Video Research reports on ratings for the most-viewed TV programs of the week. These are broken down into several categories, one of which is animation. Since 2007, the website Anime News Network has translated the animation rankings into English and posted them for readers. The archived rankings are all still available on ANN. We will attempt to compile them, to analyze them for any insights of interest.\n",
    "\n",
    "Eventually, we will be downloading almost 20 years' worth of weekly rankings, adding to around 900 web pages. We won't need to wait for one to finish loading before requesting another, so we'll want to use an asynchronous HTTP client like in `httpx`. ANN limits clients to 60 requests every 60 seconds, so we'll use the `aiolimiter` library to keep a lid on things, keeping every request inside an `async with limiter` block. To make sure we have a bit of leeway, we'll specify our allotted time-per-request to allow only 59 requests a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from httpx import AsyncClient\n",
    "from aiolimiter import AsyncLimiter\n",
    "\n",
    "limiter = AsyncLimiter(max_rate=1, time_period=60/59)\n",
    "\n",
    "async def limit_get(client: AsyncClient, url: str):\n",
    "    async with limiter:\n",
    "        response = await client.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these preliminaries observed, we turn to the contents of the pages we'll be retrieving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ranking pages\n",
    "\n",
    "First, we must know how to extract the data from any given page. Here, we will start with the URL for an archive page, such as this:\n",
    "\n",
    "https://www.animenewsnetwork.com/news/2024-12-21/japanese-animation-tv-ranking-december-9-15/.219307\n",
    "\n",
    "And we will store the ranking table in a Pandas DataFrame.\n",
    "\n",
    "Usually, this is straightforward, as there's only one `<table>` element on the page. [One post in 2015](https://www.animenewsnetwork.com/news/2015-09-17/japan-animation-tv-ranking-september-7-13/.93067) includes a summary of ratings for the recent live-action Death Note drama along with the normal table; the one we want is the second there, so we can avoid requiring special behavior by simply instructing our function to take the last table from each page.\n",
    "\n",
    "We will, however, require special behavior in another context. In the first year ANN published this column, there were several cases where two, three, or even ten weeks' worth of ratings were included in one post. We'll want them all. This should be as simple as a call to `pd.concat()`. We could check for the specific pieces, but all are known to be in 2007 or 2008, so we can just check for those years -- the single-table pages will work fine, since `pd.concat()` works with a single DataFrame as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# For future-proofing with Pandas 3.0.\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "async def get_tables_from_url(client: AsyncClient, url: str):\n",
    "    page = await limit_get(client, url)\n",
    "    return pd.read_html(io.StringIO(page))\n",
    "\n",
    "async def get_df_from_url(client: AsyncClient, url: str):\n",
    "    dfs = await get_tables_from_url(client, url)\n",
    "    if (\"news/2007\" in url) or (\"news/2008\" in url):\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        return dfs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining DataFrames from separate pages poses a problem, though. The broadcast dates are listed with the month and day, but not the year. The year is clear in the original context, but we will be combining rankings from over a decade, so \"May 5\" won't be very useful.\n",
    "\n",
    "A number of solutions are possible, but I chose to use the `Series.replace()` function in Pandas, and get the date ANN published the ranking from its URL. Under the assumption that they wouldn't have published rankings for broadcasts more than three months prior, we will make a dictionary mapping possible date strings in the relevant formats to the appropriate date objects.\n",
    "\n",
    "Normally, the broadcast dates follow a format such as \"December 8 (Sun)\". The day of week is of limited use to us, and does not follow a standard format; we will separate it into a new column for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_date_of_week(df: pd.DataFrame):\n",
    "    # A row in df['Date'] might start as \"December 8 (Sun)\".\n",
    "    date_col_split = df['Date'].str.extract(r\"(\\w+ ?\\d+) ?\\((\\w+)\\)\")\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # \"December 8\"\n",
    "    new_df['Date'] = date_col_split[0]\n",
    "    # \"Sun\"\n",
    "    new_df['Listed day of week'] = date_col_split[1]\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a function to get the date from the URL and turn it into a Python `date` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import re\n",
    "\n",
    "def get_pub_date(url: str):\n",
    "    date_string = re.search(r\"/news/([-\\d]+)/\", url)[1]\n",
    "    return date.fromisoformat(date_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to produce the dict from this date. We'll construct it from a sequence of key-value pairs, containing a string and the date that it means. These pairs can be produced with a generator.\n",
    "\n",
    "Some data quality issues comes into play here. During testing, dates were found in at least one ranking that add a leading zero to a single-digit day-of-month, though most go without. For single-digit dates, we'll have to generate strings for both options. In hopes of keeping the code readable, this will be split into a separate generator.\n",
    "\n",
    "Other cases were less easy to deal with, involving typos in the month or day that put the date outside the three-month range, clearly in error, or misspelled the month. For these cases, the best solution I found was to identify each page with a typo and include a special case for catching the misspelling. Potentially, this could also be used to catch dates with a leading zero, but at present it doesn't seem worthwhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def kvp_for_date(d: date):\n",
    "    yield (f\"{d:%B %d}\", d)\n",
    "    if d.day < 10:\n",
    "        yield (f\"{d:%B} {d.day}\", d)\n",
    "\n",
    "def typo_kvp(pub_date: date):\n",
    "    match f\"{pub_date}\":\n",
    "        case '2011-08-15':\n",
    "            yield ('August7', date(2011, 8, 7))\n",
    "        case '2015-03-30':\n",
    "            yield ('December 21', date(2015, 3, 21))\n",
    "        case '2015-10-08':\n",
    "            yield ('December 19', date(2015, 9, 19))\n",
    "        case '2016-09-24':\n",
    "            yield ('Spetember 17', date(2016, 9, 17))\n",
    "        case '2016-09-29':\n",
    "            yield ('Spetember 24', date(2016, 9, 24))\n",
    "        case '2021-05-15':\n",
    "            yield ('May 25', date(2021, 5, 2))\n",
    "        case '2022-01-29':\n",
    "            yield ('July 23', date(2022, 1, 23))\n",
    "        case '2022-02-05':\n",
    "            yield ('July 30', date(2022, 1, 30))\n",
    "\n",
    "def last_90_days_kvp(d: date):\n",
    "    for i in range(90):\n",
    "        yield from kvp_for_date(d - timedelta(days=i))\n",
    "    yield from typo_kvp(d)\n",
    "\n",
    "def last_90_days_dict(d: date):\n",
    "    return dict(last_90_days_kvp(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're ready to put it all together. We'll separate the day of week into a separate column, fix any dates that look wrong, and turn the Date column into a datetime format. While we're at it, we'll also include the first day of the week tracked (they go from Monday to Sunday) and the date Anime News Network published the ranking.\n",
    "\n",
    "One more thing: Until the 2020s, ANN's tables included an image for the anime being broadcast; these will come out as NaN in our DataFrame. Sometimes there'll also be tables with an overlooked blank row. We'll want to remove both of these with `DataFrame.dropna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_day_of_week(s: pd.Series):\n",
    "    return s.dt.to_period('W').dt.start_time\n",
    "\n",
    "def prepare_ranking_table(df: pd.DataFrame, url: str):\n",
    "    df = separate_date_of_week(df)\n",
    "\n",
    "    pub_date = get_pub_date(url)\n",
    "    last_90_days = last_90_days_dict(pub_date)\n",
    "\n",
    "    df['Date'] = df['Date'].replace(last_90_days).astype(\"datetime64[ns]\")\n",
    "    df['Publish date'] = pd.to_datetime(pub_date)\n",
    "    df['First day of week'] = first_day_of_week(df['Date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "async def get_prepared_df_from_url(client: AsyncClient, url: str):\n",
    "    try:\n",
    "        raw_df = await get_df_from_url(client, url)\n",
    "        raw_df = raw_df.dropna(axis='index', how='all')\n",
    "        raw_df = raw_df.dropna(axis='columns', how='all')\n",
    "        return prepare_ranking_table(raw_df, url)\n",
    "    except:\n",
    "        print(f\"Error getting DataFrame from {url}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple ranking pages\n",
    "\n",
    "Now, at last, we're ready to concatenate the ranking tables from separate weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def get_df_from_urls(client: AsyncClient, urls: list[str]):\n",
    "    coroutines = [get_prepared_df_from_url(client, url) for url in urls]\n",
    "    return pd.concat(await asyncio.gather(*coroutines), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to make use of this, we'll need the URLs for all the rankings.\n",
    "\n",
    "ANN has archive pages where one can view links to all news pieces in a given month or year, each with the headline and the date and time published. We'll need every monthly page back to 2007, and we'll use `BeautifulSoup` to extract the links to the TV rankings. We'll start with the function to get relevant links from a single month's archive page, then one to combine those for a year's worth.\n",
    "\n",
    "Each ANN page includes over 80 KB of overhead unrelated to the main content, so ideally, we'd want to obtain these links from the annual archive pages, to save bandwidth for both them and us. However, the ANN servers seem to have more trouble delivering 18 annual pages than 216 monthly pages in chunks of 12. This means downloading something on the order of twice as much data overall, but we can sacrifice that for the required robustness.\n",
    "\n",
    "Over the years, the format ANN's used for the titles of these articles has varied slightly, between the likes of \"Japanese Anime TV Ranking\", \"Japanese Animation TV Ranking\", \"Japan's Animation TV Ranking\". We'll use a regular expression that should capture them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "async def tv_rankings_for_month(client: AsyncClient, year: int, month: int) -> list[str]:\n",
    "    ann_base = \"https://www.animenewsnetwork.com\"\n",
    "    archive_page = await limit_get(client, f\"{ann_base}/news/{year}/{month:02}\")\n",
    "    soup = BeautifulSoup(archive_page)\n",
    "    return [\n",
    "        urljoin(ann_base, a['href'])\n",
    "        for a in soup.css.select(\".article-list li a\")\n",
    "        if re.search(r\"Anim[a-z]+ TV Ranking\", a.text)\n",
    "    ]\n",
    "\n",
    "async def tv_rankings_for_year(client: AsyncClient, year: int) -> list[str]:\n",
    "    today = date.today()\n",
    "    max = 12 if year != today.year else today.month\n",
    "    coros = [tv_rankings_for_month(client, year, m) for m in range(max, 0, -1)]\n",
    "    return [url for l in await asyncio.gather(*coros) for url in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now a function to do this for every year, and combine the URLs we need into one listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def all_ranking_urls(client: AsyncClient):\n",
    "    current_year = date.today().year\n",
    "    archive_coros = [\n",
    "        tv_rankings_for_year(client, y)\n",
    "        for y in range(current_year, 2006, -1)\n",
    "    ]\n",
    "    return [url for l in await asyncio.gather(*archive_coros) for url in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One case was found where errors were introduced due to the same article being accidentally posted twice on ANN. To adjust for that, we'll de-duplicate the URLs based on the parts before the unique article ID at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup_urls(urls: list[str]) -> list[str]:\n",
    "    return list({u.split('/.')[0]:u for u in urls}.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to get started now is the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_full_df_from_ann():\n",
    "    async with AsyncClient(timeout=None) as client:\n",
    "        urls = dedup_urls(await all_ranking_urls(client))\n",
    "        return await get_df_from_urls(client, urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, testing shows this doesn't quite work as intended -- the server starts acting up again, for reasons I confess I'm not quite clear on. So instead of combining them into one function call that uses the same client for both, we'll use a separate cell for each, creating and closing a new client both times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901 pages with TV rankings found.\n"
     ]
    }
   ],
   "source": [
    "async with AsyncClient(timeout=None) as client:\n",
    "    urls = dedup_urls(await all_ranking_urls(client))\n",
    "\n",
    "print(f\"{len(urls)} pages with TV rankings found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chibi Maruko-chan</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2025-02-02</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Apothecary Diaries</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2025-01-31</td>\n",
       "      <td>23:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doraemon</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>17:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2025-02-08</td>\n",
       "      <td>2025-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>Kakashi's Team Advances! Naruto: Shippuuden Sp...</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-04-12</td>\n",
       "      <td>19:59</td>\n",
       "      <td>55 min.</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Thurs</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>2007-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>Pururun! Shizuku-chan</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-04-14</td>\n",
       "      <td>09:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>2007-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9367</th>\n",
       "      <td>Bleach</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-04-11</td>\n",
       "      <td>19:26</td>\n",
       "      <td>29 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Wed</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>2007-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>Oha Coliseum</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-04-14</td>\n",
       "      <td>08:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>2007-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9369</th>\n",
       "      <td>Anime Major</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2007-04-14</td>\n",
       "      <td>18:00</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2007-04-19</td>\n",
       "      <td>2007-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9370 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title   Station       Date  \\\n",
       "0                                             Sazae-san   Fuji TV 2025-02-02   \n",
       "1                                       Detective Conan       NTV 2025-02-01   \n",
       "2                                     Chibi Maruko-chan   Fuji TV 2025-02-02   \n",
       "3                                The Apothecary Diaries       NTV 2025-01-31   \n",
       "4                                              Doraemon  TV Asahi 2025-02-01   \n",
       "...                                                 ...       ...        ...   \n",
       "9365  Kakashi's Team Advances! Naruto: Shippuuden Sp...  TV Tokyo 2007-04-12   \n",
       "9366                              Pururun! Shizuku-chan  TV Tokyo 2007-04-14   \n",
       "9367                                             Bleach  TV Tokyo 2007-04-11   \n",
       "9368                                       Oha Coliseum  TV Tokyo 2007-04-14   \n",
       "9369                                        Anime Major     NHK-E 2007-04-14   \n",
       "\n",
       "       Time   Length  Average Household Rating Listed day of week  \\\n",
       "0     18:30  30 min.                       8.6                Sun   \n",
       "1     18:00  30 min.                       6.1                Sat   \n",
       "2     18:00  30 min.                       5.9                Sun   \n",
       "3     23:30  30 min.                       4.2                Fri   \n",
       "4     17:00  30 min.                       3.7                Sat   \n",
       "...     ...      ...                       ...                ...   \n",
       "9365  19:59  55 min.                       5.3              Thurs   \n",
       "9366  09:30  30 min.                       5.3                Sat   \n",
       "9367  19:26  29 min.                       4.9                Wed   \n",
       "9368  08:30  30 min.                       4.9                Sat   \n",
       "9369  18:00  25 min.                       4.9                Sat   \n",
       "\n",
       "     Publish date First day of week  \n",
       "0      2025-02-08        2025-01-27  \n",
       "1      2025-02-08        2025-01-27  \n",
       "2      2025-02-08        2025-01-27  \n",
       "3      2025-02-08        2025-01-27  \n",
       "4      2025-02-08        2025-01-27  \n",
       "...           ...               ...  \n",
       "9365   2007-04-19        2007-04-09  \n",
       "9366   2007-04-19        2007-04-09  \n",
       "9367   2007-04-19        2007-04-09  \n",
       "9368   2007-04-19        2007-04-09  \n",
       "9369   2007-04-19        2007-04-09  \n",
       "\n",
       "[9370 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with AsyncClient(timeout=None) as client:\n",
    "    raw_df = await get_df_from_urls(client, urls)\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9370 entries, 0 to 9369\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Title                     9370 non-null   object        \n",
      " 1   Station                   9370 non-null   object        \n",
      " 2   Date                      9370 non-null   datetime64[ns]\n",
      " 3   Time                      9370 non-null   object        \n",
      " 4   Length                    9370 non-null   object        \n",
      " 5   Average Household Rating  9370 non-null   float64       \n",
      " 6   Listed day of week        9370 non-null   object        \n",
      " 7   Publish date              9370 non-null   datetime64[ns]\n",
      " 8   First day of week         9370 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(1), object(5)\n",
      "memory usage: 659.0+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to save our DataFrame as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def timestamped_csv(title: str, df: pd.DataFrame):\n",
    "    df.to_csv(f\"{title}_{datetime.now():%Y%m%d%H%M%S}.csv\", index=False)\n",
    "\n",
    "timestamped_csv(\"ann_tv_rankings_raw\", raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-download processing\n",
    "\n",
    "We've got more data quality issues we want to address with this data before we can really analyze it. It's good data analysis practice to make a copy of your raw data before cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a look at our `Listed day of week` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listed day of week\n",
       "Sun       4208\n",
       "Sat       2873\n",
       "Fri       1281\n",
       "Thurs      587\n",
       "Mon        167\n",
       "Wed        156\n",
       "Tues        64\n",
       "Thu         23\n",
       "Tue          5\n",
       "Sunday       4\n",
       "Monday       1\n",
       "Friday       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['Listed day of week'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, these are not in any consistent format. We'll want to unify them to DDD format. This is also a good case for use of a categorical data type, since there will only be seven possible string values when we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['Listed day of week'] = cleaned_df['Listed day of week'].replace({\n",
    "    'Thurs':  'Thu',\n",
    "    'Tues':   'Tue',\n",
    "    'Sunday': 'Sun',\n",
    "    'Monday': 'Mon',\n",
    "    'Friday': 'Fri',\n",
    "}).astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want to compare for accuracy, of course, by checking them against the date given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 of 9370 rows, or 0.80%, have mismatched days of the week.\n",
      "\n",
      "Top examples:\n",
      "Title\n",
      "Shin Sanjūshi (The New Three Musketeers)    9\n",
      "Detective Conan                             8\n",
      "Pokémon Sun & Moon                          6\n",
      "Oshiri Tantei                               5\n",
      "One Piece                                   3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "day_name = cleaned_df['Date'].dt.day_name()\n",
    "cleaned_df['Computed day of week'] = day_name.str[:3].astype('category')\n",
    "\n",
    "mismatched_dow = cleaned_df['Computed day of week'] != \\\n",
    "    cleaned_df['Listed day of week']\n",
    "n, d = mismatched_dow.sum(), len(cleaned_df)\n",
    "print(f\"{n} of {d} rows, or {n/d:.2%}, have mismatched days of the week.\")\n",
    "\n",
    "if n > 0:\n",
    "    print(\"\\nTop examples:\")\n",
    "    print(cleaned_df.loc[mismatched_dow, 'Title'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we have some errors -- and it's hard to be sure whether the date or day of week listed is correct. Consider the case of the popular anime Detective Conan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Listed day of week  Computed day of week\n",
       "Sat                 Sat                     767\n",
       "Mon                 Mon                      30\n",
       "                    Sat                       8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[\n",
    "    (cleaned_df['Title'] == \"Detective Conan\"),\n",
    "    ['Listed day of week', 'Computed day of week']\n",
    "].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both columns are in agreement that the series is usually broadcast on Saturday, but at times it's been broadcast on Monday. Without digging deeper, it's hard to be sure which is correct for the eight discrepancies -- where a Saturday broadcast date was listed as a Monday. We might compare an additional source with broadcast dates for error correction, or investigate each series one by one -- perhaps the regular broadcast day was changed at some point, and that knowledge can be used to pick the correct day based on whether the episode was broadcast before them or after. For now, we will leave the data as is, with a caution that the day-and-date broadcast info cannot be relied on for almost 1% of all rows.\n",
    "\n",
    "Another sure sign of errors can be found by searching for cases of multiple programs apparently being broadcast on the same channel at the exact same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>My Hero Academia</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2021-08-07</td>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>9:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>9:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>Pokémon Sun &amp; Moon</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>18:55</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>Pokémon Sun &amp; Moon</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>18:55</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>Animated O-saru no George (Curious George)</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>08:35</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>Animated O-saru no George (Curious George)</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>08:35</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>2.8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>Crayon Shin-chan</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>19:30</td>\n",
       "      <td>24 min.</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>Crayon Shin-chan</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>19:30</td>\n",
       "      <td>24 min.</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-11-16</td>\n",
       "      <td>2017-11-06</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>Animated O-saru no George (Curious George)</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>08:35</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>Animated O-saru no George (Curious George)</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>08:35</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>11.1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2016-07-03</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2016-07-07</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>Pokémon XY &amp; Z</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2016-02-11</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>Pokémon XY &amp; Z</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5219</th>\n",
       "      <td>Go! Princess Precure</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2015-05-24</td>\n",
       "      <td>08:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5229</th>\n",
       "      <td>Go! Princess Precure</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2015-05-24</td>\n",
       "      <td>08:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>2015-05-18</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>Magic Kaito 1412 (Last Episode)</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2015-04-08</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>Magic Kaito 1412</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>2015-02-23</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>Crayon Shin-chan</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2010-12-03</td>\n",
       "      <td>19:00</td>\n",
       "      <td>24 min.</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2010-12-12</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7583</th>\n",
       "      <td>Doraemon</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2010-12-03</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2010-12-12</td>\n",
       "      <td>2010-11-29</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8233</th>\n",
       "      <td>One Piece</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-09-13</td>\n",
       "      <td>09:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>11.2</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2009-09-19</td>\n",
       "      <td>2009-09-07</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>Dragon Ball Kai</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-09-13</td>\n",
       "      <td>09:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2009-09-19</td>\n",
       "      <td>2009-09-07</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2009-04-04</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Mon</td>\n",
       "      <td>2009-04-16</td>\n",
       "      <td>2009-03-30</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2009-04-04</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Mon</td>\n",
       "      <td>2009-04-13</td>\n",
       "      <td>2009-03-30</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>Pocket Monsters: Diamond &amp; Pearl</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2008-08-28</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-09-07</td>\n",
       "      <td>2008-08-25</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>Naruto Shippūden</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2008-08-28</td>\n",
       "      <td>19:00</td>\n",
       "      <td>27 min.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-09-07</td>\n",
       "      <td>2008-08-25</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>Chibi Maruko-chan</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-04-20</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>2008-04-14</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>Chibi Maruko-chan</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-04-20</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>13.9</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2008-04-24</td>\n",
       "      <td>2008-04-14</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>Pocket Monsters DP</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-10-18</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-11-30</td>\n",
       "      <td>2007-10-15</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9250</th>\n",
       "      <td>Anime Pocket Monsters Broadcast 10th Anniversa...</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>2007-10-18</td>\n",
       "      <td>19:00</td>\n",
       "      <td>114 min.</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-11-30</td>\n",
       "      <td>2007-10-15</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title   Station       Date  \\\n",
       "1932                                    Detective Conan       NTV 2021-07-31   \n",
       "1936                                   My Hero Academia       NTV 2021-07-31   \n",
       "3380                                          One Piece   Fuji TV 2018-11-11   \n",
       "3390                                          One Piece   Fuji TV 2018-11-11   \n",
       "3799                                 Pokémon Sun & Moon  TV Tokyo 2018-01-25   \n",
       "3808                                 Pokémon Sun & Moon  TV Tokyo 2018-01-25   \n",
       "3858         Animated O-saru no George (Curious George)     NHK-E 2017-12-16   \n",
       "3870         Animated O-saru no George (Curious George)     NHK-E 2017-12-16   \n",
       "3903                                   Crayon Shin-chan  TV Asahi 2017-11-10   \n",
       "3904                                    Detective Conan       NTV 2017-11-11   \n",
       "3914                                   Crayon Shin-chan  TV Asahi 2017-11-10   \n",
       "3915                                    Detective Conan       NTV 2017-11-11   \n",
       "4294         Animated O-saru no George (Curious George)     NHK-E 2017-02-18   \n",
       "4305         Animated O-saru no George (Curious George)     NHK-E 2017-02-18   \n",
       "4624                                          Sazae-san   Fuji TV 2016-07-03   \n",
       "4635                                          Sazae-san   Fuji TV 2016-07-03   \n",
       "4858                                     Pokémon XY & Z  TV Tokyo 2016-01-14   \n",
       "4887                                     Pokémon XY & Z  TV Tokyo 2016-01-14   \n",
       "5219                               Go! Princess Precure  TV Asahi 2015-05-24   \n",
       "5229                               Go! Princess Precure  TV Asahi 2015-05-24   \n",
       "5296                    Magic Kaito 1412 (Last Episode)       NTV 2015-02-28   \n",
       "5338                                   Magic Kaito 1412       NTV 2015-02-28   \n",
       "7581                                   Crayon Shin-chan  TV Asahi 2010-12-03   \n",
       "7583                                           Doraemon  TV Asahi 2010-12-03   \n",
       "8233                                          One Piece   Fuji TV 2009-09-13   \n",
       "8234                                    Dragon Ball Kai   Fuji TV 2009-09-13   \n",
       "8445                                    Detective Conan       NTV 2009-04-04   \n",
       "8456                                    Detective Conan       NTV 2009-04-04   \n",
       "8771                   Pocket Monsters: Diamond & Pearl  TV Tokyo 2008-08-28   \n",
       "8772                                   Naruto Shippūden  TV Tokyo 2008-08-28   \n",
       "8947                                  Chibi Maruko-chan   Fuji TV 2008-04-20   \n",
       "8957                                  Chibi Maruko-chan   Fuji TV 2008-04-20   \n",
       "9232                                 Pocket Monsters DP  TV Tokyo 2007-10-18   \n",
       "9250  Anime Pocket Monsters Broadcast 10th Anniversa...  TV Tokyo 2007-10-18   \n",
       "\n",
       "       Time    Length  Average Household Rating Listed day of week  \\\n",
       "1932  17:30   30 min.                       4.0                Sat   \n",
       "1936  17:30   30 min.                       3.2                Sat   \n",
       "3380   9:30   30 min.                       5.6                Sun   \n",
       "3390   9:30   30 min.                       5.0                Sun   \n",
       "3799  18:55   30 min.                       3.5                Thu   \n",
       "3808  18:55   30 min.                       3.8                Thu   \n",
       "3858  08:35   25 min.                       3.5                Sat   \n",
       "3870  08:35   25 min.                       2.8                Sat   \n",
       "3903  19:30   24 min.                       8.3                Fri   \n",
       "3904  18:00   30 min.                       7.8                Sat   \n",
       "3914  19:30   24 min.                       8.5                Fri   \n",
       "3915  18:00   30 min.                       7.3                Sat   \n",
       "4294  08:35   25 min.                       3.8                Sat   \n",
       "4305  08:35   25 min.                       3.9                Sat   \n",
       "4624  18:30   30 min.                      11.1                Sun   \n",
       "4635  18:30   30 min.                       9.9                Sun   \n",
       "4858  19:00   30 min.                       3.9                Thu   \n",
       "4887  19:00   30 min.                       3.5                Thu   \n",
       "5219  08:30   30 min.                       4.0                Sun   \n",
       "5229  08:30   30 min.                       3.8                Sun   \n",
       "5296  17:30   30 min.                       6.1                Sat   \n",
       "5338  17:30   30 min.                       6.1                Sat   \n",
       "7581  19:00   24 min.                       9.9                Fri   \n",
       "7583  19:00   30 min.                       8.9                Fri   \n",
       "8233  09:30   30 min.                      11.2                Sun   \n",
       "8234  09:30   30 min.                       9.1                Sun   \n",
       "8445  18:00   30 min.                       7.0                Mon   \n",
       "8456  18:00   30 min.                       6.9                Mon   \n",
       "8771  19:00   30 min.                       6.8                Thu   \n",
       "8772  19:00   27 min.                       6.0                Thu   \n",
       "8947  18:00   30 min.                      11.6                Sun   \n",
       "8957  18:00   30 min.                      13.9                Sun   \n",
       "9232  19:00   30 min.                       7.5                Thu   \n",
       "9250  19:00  114 min.                       7.3                Thu   \n",
       "\n",
       "     Publish date First day of week Computed day of week  \n",
       "1932   2021-08-07        2021-07-26                  Sat  \n",
       "1936   2021-08-07        2021-07-26                  Sat  \n",
       "3380   2018-11-22        2018-11-05                  Sun  \n",
       "3390   2018-11-15        2018-11-05                  Sun  \n",
       "3799   2018-02-08        2018-01-22                  Thu  \n",
       "3808   2018-02-01        2018-01-22                  Thu  \n",
       "3858   2017-12-28        2017-12-11                  Sat  \n",
       "3870   2017-12-21        2017-12-11                  Sat  \n",
       "3903   2017-11-23        2017-11-06                  Fri  \n",
       "3904   2017-11-23        2017-11-06                  Sat  \n",
       "3914   2017-11-16        2017-11-06                  Fri  \n",
       "3915   2017-11-16        2017-11-06                  Sat  \n",
       "4294   2017-03-02        2017-02-13                  Sat  \n",
       "4305   2017-02-23        2017-02-13                  Sat  \n",
       "4624   2016-07-14        2016-06-27                  Sun  \n",
       "4635   2016-07-07        2016-06-27                  Sun  \n",
       "4858   2016-02-11        2016-01-11                  Thu  \n",
       "4887   2016-01-21        2016-01-11                  Thu  \n",
       "5219   2015-06-08        2015-05-18                  Sun  \n",
       "5229   2015-06-01        2015-05-18                  Sun  \n",
       "5296   2015-04-08        2015-02-23                  Sat  \n",
       "5338   2015-03-09        2015-02-23                  Sat  \n",
       "7581   2010-12-12        2010-11-29                  Fri  \n",
       "7583   2010-12-12        2010-11-29                  Fri  \n",
       "8233   2009-09-19        2009-09-07                  Sun  \n",
       "8234   2009-09-19        2009-09-07                  Sun  \n",
       "8445   2009-04-16        2009-03-30                  Sat  \n",
       "8456   2009-04-13        2009-03-30                  Sat  \n",
       "8771   2008-09-07        2008-08-25                  Thu  \n",
       "8772   2008-09-07        2008-08-25                  Thu  \n",
       "8947   2008-05-05        2008-04-14                  Sun  \n",
       "8957   2008-04-24        2008-04-14                  Sun  \n",
       "9232   2007-11-30        2007-10-15                  Thu  \n",
       "9250   2007-11-30        2007-10-15                  Thu  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup = cleaned_df.duplicated(subset=['Station', 'Date', 'Time'], keep=False)\n",
    "cleaned_df.loc[dup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 errors detected through duplicates.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dup.sum() // 2} errors detected through duplicates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These, again, will need to be inspected on a case-by-case basis, to determine which fields in which rows are in error.\n",
    "\n",
    "Setting that aside for now, we'll shift our focus to the `Station` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "Fuji TV        3369\n",
       "TV Asahi       2229\n",
       "NTV            1650\n",
       "TV Tokyo       1059\n",
       "NHK-E           887\n",
       "TBS             104\n",
       "NHK              41\n",
       "NHK-G            23\n",
       "NHK General       6\n",
       "TV-TOKYO          1\n",
       "Nippon TV         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['Station'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with `Listed day of week`, there are a few inconsistencies in the names used for stations, and so we'll normalize them the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "Fuji TV     3369\n",
       "TV Asahi    2229\n",
       "NTV         1651\n",
       "TV Tokyo    1060\n",
       "NHK-E        887\n",
       "TBS          104\n",
       "NHK           70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['Station'] = cleaned_df['Station'].replace({\n",
    "    'NHK-G':       'NHK',\n",
    "    'NHK General': 'NHK',\n",
    "    'TV-TOKYO':    'TV Tokyo',\n",
    "    'Nippon TV':   'NTV',\n",
    "}).astype('category')\n",
    "\n",
    "cleaned_df['Station'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seven national terrestrial networks, two public and five commercial, are represented. TBS has the fewest appearances of the commercial networks, though it does have some standout franchises like Gundam and Jujutsu Kaisen. Of note, independent UHF stations like [Tokyo MX](https://en.wikipedia.org/wiki/Tokyo_MX) are completely absent. This could be because none of their anime have ever had enough live viewers, though it may also be that Video Research undercounts viewership rates for these stations because they have less signal power, and therefore reach fewer viewers.\n",
    "\n",
    "For example, the anime Oshi no Ko and Mobile Suit Gundam: The Witch from Mercury were both popular in the spring of 2023. But everyone in Kanto who watched The Witch from Mercury with a TV antenna did so on TBS, while Oshi no Ko's Kanto viewers would've watched it on Tokyo MX in Tokyo, [TV Kanagawa](https://en.wikipedia.org/wiki/Television_Kanagawa) in Yokohama, [Gunma TV](https://en.wikipedia.org/wiki/Gunma_Television) in Maebashi, and so on. If Video Research counts viewers of those broadcasts separately, the viewership numbers for Oshi no Ko would be fragmented. This could explain why Oshi no Ko never charted in this time and The Witch from Mercury did, even though Google Trends [suggests](https://trends.google.com/trends/explore?date=2023-01-01%202023-12-31&geo=JP&q=%E6%8E%A8%E3%81%97%E3%81%AE%E5%AD%90,%E6%B0%B4%E6%98%9F%E3%81%AE%E9%AD%94%E5%A5%B3,%E9%AC%BC%E6%BB%85%E3%81%AE%E5%88%83,%E3%82%AC%E3%83%B3%E3%83%80%E3%83%A0&hl=en-US) there was more interest in Oshi no Ko than The Witch from Mercury at the time, or even Demon Slayer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll check to see that the `Average Household Rating` values are what we'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9370.000000\n",
       "mean        6.691686\n",
       "std         3.880626\n",
       "min         0.600000\n",
       "25%         3.700000\n",
       "50%         5.800000\n",
       "75%         8.800000\n",
       "max        85.000000\n",
       "Name: Average Household Rating, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['Average Household Rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a clear outlier; it's very unlikely an anime broadcast gained an 85% viewership rating in the 21st century. Let's look closer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2010-11-21</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2010-11-27</td>\n",
       "      <td>2010-11-15</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>24.2</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2011-02-06</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7518</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>24.3</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2011-01-23</td>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>Sazae-san</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2010-10-24</td>\n",
       "      <td>18:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>24.7</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2010-11-08</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>Chibi Maruko-chan</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title  Station       Date   Time   Length  \\\n",
       "7598          Sazae-san  Fuji TV 2010-11-21  18:30  30 min.   \n",
       "7497          Sazae-san  Fuji TV 2011-01-30  18:30  30 min.   \n",
       "7518          Sazae-san  Fuji TV 2011-01-16  18:30  30 min.   \n",
       "7639          Sazae-san  Fuji TV 2010-10-24  18:30  30 min.   \n",
       "2767  Chibi Maruko-chan  Fuji TV 2020-01-05  18:00  30 min.   \n",
       "\n",
       "      Average Household Rating Listed day of week Publish date  \\\n",
       "7598                      24.0                Sun   2010-11-27   \n",
       "7497                      24.2                Sun   2011-02-06   \n",
       "7518                      24.3                Sun   2011-01-23   \n",
       "7639                      24.7                Sun   2010-11-08   \n",
       "2767                      85.0                Sun   2020-01-17   \n",
       "\n",
       "     First day of week Computed day of week  \n",
       "7598        2010-11-15                  Sun  \n",
       "7497        2011-01-24                  Sun  \n",
       "7518        2011-01-10                  Sun  \n",
       "7639        2010-10-18                  Sun  \n",
       "2767        2019-12-30                  Sun  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.sort_values(by='Average Household Rating').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anime News Network's archives can also be accessed by the day. [Pasting in the relevant date](https://animenewsnetwork.com/news/2020-01-17), we can quickly find our ranking, where we see the problem: Chibi Maruko-chan's 8.5 rating was mistyped with a comma. Let's correct that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>Chibi Maruko-chan</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Title  Station       Date   Time   Length  \\\n",
       "2767  Chibi Maruko-chan  Fuji TV 2020-01-05  18:00  30 min.   \n",
       "\n",
       "      Average Household Rating Listed day of week Publish date  \\\n",
       "2767                       8.5                Sun   2020-01-17   \n",
       "\n",
       "     First day of week Computed day of week  \n",
       "2767        2019-12-30                  Sun  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marukochan85 = cleaned_df['Average Household Rating'] == 85\n",
    "\n",
    "cleaned_df.loc[marukochan85, 'Average Household Rating'] = 8.5\n",
    "cleaned_df.loc[marukochan85]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our only real outlier -- the Sazae-san ratings are quite plausible for that period. Let's turn to the `Length` and `Time` columns, which you'll have noticed have a typical format -- let's see if any rows don't fit those formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>Anime Major 4</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>9:14 11:16</td>\n",
       "      <td>24 min. 25 min.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>Anime Major 4</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>8:00 8:49 9:38 10:03 10:52</td>\n",
       "      <td>24-25 min.</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title Station       Date                        Time  \\\n",
       "7545  Anime Major 4   NHK-E 2011-01-01                  9:14 11:16   \n",
       "7546  Anime Major 4   NHK-E 2011-01-01  8:00 8:49 9:38 10:03 10:52   \n",
       "\n",
       "               Length  Average Household Rating Listed day of week  \\\n",
       "7545  24 min. 25 min.                       2.0                Sat   \n",
       "7546       24-25 min.                       1.9                Sat   \n",
       "\n",
       "     Publish date First day of week Computed day of week  \n",
       "7545   2011-01-16        2010-12-27                  Sat  \n",
       "7546   2011-01-16        2010-12-27                  Sat  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[~cleaned_df['Length'].str.fullmatch(r\"\\d+ min\\.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>Anime Major 4</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>9:14 11:16</td>\n",
       "      <td>24 min. 25 min.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>Anime Major 4</td>\n",
       "      <td>NHK-E</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>8:00 8:49 9:38 10:03 10:52</td>\n",
       "      <td>24-25 min.</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Title Station       Date                        Time  \\\n",
       "7545  Anime Major 4   NHK-E 2011-01-01                  9:14 11:16   \n",
       "7546  Anime Major 4   NHK-E 2011-01-01  8:00 8:49 9:38 10:03 10:52   \n",
       "\n",
       "               Length  Average Household Rating Listed day of week  \\\n",
       "7545  24 min. 25 min.                       2.0                Sat   \n",
       "7546       24-25 min.                       1.9                Sat   \n",
       "\n",
       "     Publish date First day of week Computed day of week  \n",
       "7545   2011-01-16        2010-12-27                  Sat  \n",
       "7546   2011-01-16        2010-12-27                  Sat  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[~cleaned_df['Time'].str.fullmatch(r\"\\d+:\\d+\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In only one case does either column diverge from the norm: On the morning of New Year's Day 2011, NHK Educational TV seems to have broadcast several episodes of the baseball anime Major. If we want to convert these columns to numeric formats, we'll have to decide what to do about them. We could just remove them altogether, or if we can find a viable source for which broadcasts were which lengths, we could split these two columns into seven.\n",
    "\n",
    "There is one other obstacle to making use of the time column: the 30-hour system used by Japanese TV schedules. Typically, late-night broadcast times from midnight to 6 AM are listed as though they were an extension of the previous day, under the logic that viewers staying up late to watch experience them that way. Instead of 02:00 Friday, for example, a time might be written as 26:00 Thursday. Anime News Network usually corrects these to standard time, but not always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "0       55\n",
       "1       16\n",
       "2        2\n",
       "4        1\n",
       "5        2\n",
       "6       34\n",
       "7       47\n",
       "8     1177\n",
       "9     1935\n",
       "10     155\n",
       "11      36\n",
       "12       4\n",
       "13       9\n",
       "14       1\n",
       "15       6\n",
       "16     280\n",
       "17     915\n",
       "18    2856\n",
       "19    1637\n",
       "21      41\n",
       "22       3\n",
       "23     157\n",
       "24       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour = cleaned_df['Time'].str.split(':').str[0].astype(int)\n",
    "hour.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>Attack on Titan The Final Season</td>\n",
       "      <td>NHK</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>24:10</td>\n",
       "      <td>25 min.</td>\n",
       "      <td>2.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>2021-02-08</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Station       Date   Time   Length  \\\n",
       "2182  Attack on Titan The Final Season     NHK 2021-02-14  24:10  25 min.   \n",
       "\n",
       "      Average Household Rating Listed day of week Publish date  \\\n",
       "2182                       2.6                Sun   2021-02-19   \n",
       "\n",
       "     First day of week Computed day of week  \n",
       "2182        2021-02-08                  Sun  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df[hour >= 24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each row only has a single time (which will be the case if we adjust the Major marathon above), the `Date` and `Time` columns can be merged into a single column of dtype `datetime64[ns]` by adding the latter's hours and minutes to the former, as though it represented a timedelta. This will normalize any listed times of 24:00 or later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d has dtype datetime64[ns], containing the start of each date.\n",
    "# t has dtype object, containing strings representing the broadcast time.\n",
    "def pandas_process_30hour(d: pd.Series, t: pd.Series):\n",
    "    assert t.str.fullmatch(r\"\\d+:\\d+\").all()\n",
    "    return d + pd.to_timedelta(t+':00')\n",
    "\n",
    "# If we allow multiple times in one row, using this instead will create a\n",
    "# datetime column based on the first time listed.\n",
    "def pandas_process_30hour_multitime(d: pd.Series, t: pd.Series):\n",
    "    times = t.str.split().str.len()\n",
    "    first_time = t.str.split(expand=True)[0]\n",
    "    return d + pd.to_timedelta(first_time+':00'), times\n",
    "\n",
    "def add_datetime_col(df: pd.DataFrame):\n",
    "    dt = pandas_process_30hour(df['Date'], df['Time'])\n",
    "    df['Datetime'] = dt\n",
    "    return df\n",
    "\n",
    "def add_datetime_col_multitime(df: pd.DataFrame):\n",
    "    dt, n = pandas_process_30hour_multitime(df['Date'], df['Time'])\n",
    "    df['Datetime'] = dt\n",
    "    df['Times listed'] = n\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're not converting the times from strings, we may still want to standardize the format for times before 10:00 -- some such times in the data have leading zeroes, and some don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973 with a leading zero, 294 without.\n"
     ]
    }
   ],
   "source": [
    "leading_zero = cleaned_df['Time'].str.fullmatch(r\"0\\d:\\d+\")\n",
    "no_leading_zero = cleaned_df['Time'].str.fullmatch(r\"\\d:\\d+\")\n",
    "\n",
    "print(f\"{leading_zero.sum()} with a leading zero, {no_leading_zero.sum()} without.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After revision:\n",
      "3267 with a leading zero, 0 without.\n"
     ]
    }
   ],
   "source": [
    "cleaned_df['Time'] = cleaned_df['Time'].str.zfill(5)\n",
    "\n",
    "leading_zero = cleaned_df['Time'].str.fullmatch(r\"0\\d:\\d+\")\n",
    "no_leading_zero = cleaned_df['Time'].str.fullmatch(r\"\\d:\\d+\")\n",
    "\n",
    "print(f\"After revision:\")\n",
    "print(f\"{leading_zero.sum()} with a leading zero, {no_leading_zero.sum()} without.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights\n",
    "\n",
    "While some data quality issues remain, there are still questions that can be answered, and insights gained, from the data we have. For example, from the distribution of hours above, we can see that the most-viewed anime are largely concentrated in the early evening and the morning, with a smaller grouping late at night. This invites a first question: What have been the most-viewed anime at different times of day?\n",
    "\n",
    "We already have a series giving the hour for each airtime, so it makes sense to reuse that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_programs_for_hour(h: int, n: int):\n",
    "    # h: An hour of the day.\n",
    "    # n: How many distinct combinations of show/station/day/time\n",
    "    #    we want to display.\n",
    "    return cleaned_df.loc[\n",
    "        hour == h,\n",
    "        ['Title', 'Station', 'Listed day of week', 'Time']\n",
    "    ].value_counts().head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by looking at the morning hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                       Station   Listed day of week  Time \n",
       "Animated O-saru no George (Curious George)  NHK-E     Sat                 08:35    370\n",
       "Soaring Sky! Pretty Cure                    TV Asahi  Sun                 08:30     48\n",
       "Wonderful Precure!                          TV Asahi  Sun                 08:30     47\n",
       "Fresh Precure!                              TV Asahi  Sun                 08:30     46\n",
       "Smile Precure!                              TV Asahi  Sun                 08:30     45\n",
       "Hugtto! Precure                             TV Asahi  Sun                 08:30     45\n",
       "Heartcatch Precure!                         TV Asahi  Sun                 08:30     44\n",
       "Star ☆ Twinkle Precure                      TV Asahi  Sun                 08:30     43\n",
       "Tropical-Rouge! Precure                     TV Asahi  Sun                 08:30     43\n",
       "Dokidoki! Precure                           TV Asahi  Sun                 08:30     43\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_programs_for_hour(8, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious George has the highest individual count, but the rest of the chart is dominated by Toei Animation and TV Asahi's hugely popular girls' superhero series Pretty Cure (\"Precure\" for short), which changes its title once a year. In this case, we can use a regular expression to group them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 1177 listings for the 08:00-09:00 hour are composed of 729 for Pretty Cure, 386 for Curious George, and 62 for other anime.\n"
     ]
    }
   ],
   "source": [
    "hour8 = hour == 8\n",
    "hour8_sum = hour8.sum()\n",
    "hour8_titles = cleaned_df.loc[hour8, 'Title']\n",
    "precure_sum = hour8_titles.str.contains(r\"Pre.+ure\").sum()\n",
    "george_sum = hour8_titles.str.contains(r\"Curious George\").sum()\n",
    "\n",
    "print(\n",
    "    f\"The {hour8_sum} listings for the 08:00-09:00 hour are composed of \"\n",
    "    f\"{precure_sum} for Pretty Cure, {george_sum} for Curious George, and \"\n",
    "    f\"{hour8_sum - precure_sum - george_sum} for other anime.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers for Curious George differ slightly due to occasional variations in time and air title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                                 Time \n",
       "Animated O-saru no George (Curious George)            08:35    370\n",
       "                                                      08:00      8\n",
       "                                                      08:30      2\n",
       "Animated O-saru no George (Curious George) Selection  08:35      2\n",
       "Animated O-saru no George (Curious George)            08:10      1\n",
       "                                                      08:25      1\n",
       "Animated O-saru no George (Curious George) Selection  08:20      1\n",
       "Animated O-saru no George (Curious George) Special    08:25      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[\n",
    "    hour8 & cleaned_df['Title'].str.contains(r\"Curious George\"),\n",
    "    ['Title', 'Time']\n",
    "].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the remaining morning listings are for the 9:00 hour, which we'll examine next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                         Station  Listed day of week  Time \n",
       "One Piece                                     Fuji TV  Sun                 09:30    843\n",
       "Oshiri Tantei                                 NHK-E    Sat                 09:00    223\n",
       "Toriko                                        Fuji TV  Sun                 09:00    139\n",
       "Dragon Ball Super                             Fuji TV  Sun                 09:00    128\n",
       "Animation Hitsuji no Shaun (Shaun the Sheep)  NHK-E    Sat                 09:00     97\n",
       "GeGeGe no Kitarō                              Fuji TV  Sun                 09:00     96\n",
       "Dragon Ball Kai                               Fuji TV  Sun                 09:00     94\n",
       "Gegege no Kitarō                              Fuji TV  Sun                 09:00     89\n",
       "Dragon Ball Z Kai                             Fuji TV  Sun                 09:00     58\n",
       "One Piece Special Edition                     Fuji TV  Sat                 09:55     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_programs_for_hour(9, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hour is dominated by One Piece, which aired on Sundays at 9:30 AM from 2006 to 2025. It's also clear that Fuji TV has aired a variety of anime in the immediately preceding timeslot with good results, including two entries into the GeGeGe no Kitarō franchise, Dragon Ball Kai and Super, and from 2011-2014, Toriko. The timeslot has also broadcast most Digimon series since the original Digimon Adventure -- see the Japanese Wikipedia's article on [Fuji TV's 9 AM Sunday anime slot](https://ja.wikipedia.org/wiki/%E3%83%95%E3%82%B8%E3%83%86%E3%83%AC%E3%83%93%E6%97%A5%E6%9B%9C%E6%9C%9D9%E6%99%82%E5%8F%B0%E6%9E%A0%E3%81%AE%E3%82%A2%E3%83%8B%E3%83%A1) for more details.\n",
    "\n",
    "Looking at these two listings together, it's clear that the most popular morning anime are broadcast on weekends -- which stands to reason, as most of the audience will be away from home on weekday mornings. A division by day and station is also apparent. On Saturday mornings, the most-watched anime are on NHK Educational TV's [E-Tele Kids](https://ja.wikipedia.org/wiki/E%E3%83%86%E3%83%AC%E3%82%AD%E3%83%83%E3%82%BA) block for preschoolers, but Sunday mornings are for their older siblings' favorite action shows. One can imagine a young girl waking up and turning on TV Asahi to watch Pretty Cure at 8:30, then sticking around for Kamen Rider immediately afterward -- instead of staying for Super Sentai in the second half of [Super Hero Time](https://en.wikipedia.org/wiki/Super_Hero_Time), though, she changes the channel to Fuji TV for One Piece.\n",
    "\n",
    "All this highlights the significance of timeslots to anime broadcasting. Their importance in TV broadcasting generally is common sense, but international anime fans are almost entirely divorced from the way TV anime is originally broadcast in Japan, so timeslots can easily become invisible. Consider another timeslot that has proven significant for viewership: [Yomiuri TV's Saturday evening anime](https://ja.wikipedia.org/wiki/%E8%AA%AD%E5%A3%B2%E3%83%86%E3%83%AC%E3%83%93%E5%88%B6%E4%BD%9C%E5%9C%9F%E6%9B%9C%E5%A4%95%E6%96%B9%E6%9E%A0%E3%81%AE%E3%82%A2%E3%83%8B%E3%83%A1), with the enormously popular Detective Conan at 6:00 PM since 2009, and another anime immediately before since 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Average Household Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>Yashahime: Princess Half-Demon - The Second Act</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-02-01</th>\n",
       "      <td>Yashahime: Princess Half-Demon - The Second Act</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>Love All Play (debut)</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>Love All Play</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>Love All Play</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>My Hero Academia Season 6 (Premiere)</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>My Hero Academia Season 6</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01</th>\n",
       "      <td>My Hero Academia Season 6</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>MIX Season 2 (premiere)</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>MIX Season 2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>MIX Season 2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>Firefighter Daigo: Rescuer in Orange</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>Firefighter Daigo: Rescuer in Orange</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>Firefighter Daigo: Rescuer in Orange</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>My Hero Academia Memories</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>My Hero Academia season 7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>My Hero Academia season 7</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>My Hero Academia season 7</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-01</th>\n",
       "      <td>Blue Miburo</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-01</th>\n",
       "      <td>Blue Miburo</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Title  \\\n",
       "Date                                                          \n",
       "2021-12-01  Yashahime: Princess Half-Demon - The Second Act   \n",
       "2022-02-01  Yashahime: Princess Half-Demon - The Second Act   \n",
       "2022-04-01                            Love All Play (debut)   \n",
       "2022-06-01                                    Love All Play   \n",
       "2022-08-01                                    Love All Play   \n",
       "2022-10-01             My Hero Academia Season 6 (Premiere)   \n",
       "2022-12-01                        My Hero Academia Season 6   \n",
       "2023-02-01                        My Hero Academia Season 6   \n",
       "2023-04-01                          MIX Season 2 (premiere)   \n",
       "2023-06-01                                     MIX Season 2   \n",
       "2023-08-01                                     MIX Season 2   \n",
       "2023-10-01             Firefighter Daigo: Rescuer in Orange   \n",
       "2023-12-01             Firefighter Daigo: Rescuer in Orange   \n",
       "2024-02-01             Firefighter Daigo: Rescuer in Orange   \n",
       "2024-04-01                        My Hero Academia Memories   \n",
       "2024-06-01                        My Hero Academia season 7   \n",
       "2024-08-01                        My Hero Academia season 7   \n",
       "2024-10-01                        My Hero Academia season 7   \n",
       "2024-12-01                                      Blue Miburo   \n",
       "2025-02-01                                      Blue Miburo   \n",
       "\n",
       "            Average Household Rating  \n",
       "Date                                  \n",
       "2021-12-01                       4.0  \n",
       "2022-02-01                       4.8  \n",
       "2022-04-01                       3.1  \n",
       "2022-06-01                       3.3  \n",
       "2022-08-01                       2.9  \n",
       "2022-10-01                       3.9  \n",
       "2022-12-01                       5.3  \n",
       "2023-02-01                       3.6  \n",
       "2023-04-01                       3.1  \n",
       "2023-06-01                       2.8  \n",
       "2023-08-01                       3.2  \n",
       "2023-10-01                       3.7  \n",
       "2023-12-01                       3.7  \n",
       "2024-02-01                       3.5  \n",
       "2024-04-01                       3.5  \n",
       "2024-06-01                       2.5  \n",
       "2024-08-01                       2.8  \n",
       "2024-10-01                       3.4  \n",
       "2024-12-01                       3.5  \n",
       "2025-02-01                       3.1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_conan_slot = ((cleaned_df['Station'] == 'NTV')\n",
    "& (cleaned_df['Time'] == '17:30')\n",
    "& (cleaned_df['Listed day of week'] == 'Sat'))\n",
    "\n",
    "cleaned_df.loc[\n",
    "    pre_conan_slot,\n",
    "    ['Title', 'Date', 'Average Household Rating']\n",
    "].groupby(pd.Grouper(key='Date', freq='2MS')).first().tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 5:30 PM timeslot's occupant has changed every six months since 2014. Of the series that have aired in that time, the most prominent internationally is by far My Hero Academia, which has aired in this slot since its second season. Others, such as the Ace Attorney anime or the Inuyasha sequel Yashahime, have much smaller international followings, but are still recognizable in fan circles. Hoever, those same viewers may be puzzled to find series they've never heard of on these rankings, such as Blue Miburo, Firefighter Daigo: Rescuer in Orange, Love All Play, or Hakushon Daimaō 2020. Such is the power of a valuable timeslot.\n",
    "\n",
    "According to [figures published by the Association of Japanese Animations](https://aja.gr.jp/english/japan-anime-data), every year since 2015, a majority of minutes of TV anime produced have been for late-night anime -- a relatively new trend, as daytime minutes exceeded late-night minutes by more than 2:1 as recently as 2003, and late-night anime broadcasts were not common at all before 1996. Today, not only does late-night anime account for a majority of production, it makes up the vast majority of anime watched by international viewers. As we have seen, however, it is relatively uncommon in the live viewership rankings, for understandable reasons of convenience, and perhaps also because the bulk of them air on independent stations. It's worth knowing what the exceptions have been."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Frieren: Beyond Journey's End                                23\n",
       "That Time I Got Reincarnated as a Slime season 3             21\n",
       "Spy×Family                                                   18\n",
       "Lupin the 3rd Part 6                                         14\n",
       "Dragon Ball Daima                                            11\n",
       "Demon Slayer: Kimetsu no Yaiba Entertainment District Arc    10\n",
       "Jujutsu Kaisen season 2                                      10\n",
       "Demon Slayer: Kimetsu no Yaiba Swordsmith Village Arc         9\n",
       "The Apothecary Diaries                                        7\n",
       "Demon Slayer: Kimetsu no Yaiba Hashira Training Arc           6\n",
       "Demon Slayer: Kimetsu no Yaiba Mugen Train Arc                6\n",
       "Magilumiere Co. Ltd.                                          6\n",
       "Spy×Family season 2                                           5\n",
       "Attack on Titan The Final Season                              3\n",
       "Edens Zero                                                    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "late_night = (hour < 6) | (hour > 20)\n",
    "cleaned_df.loc[late_night, 'Title'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every season of the overwhelmingly popular Demon Slayer: Kimetsu no Yaiba after its first is well-represented. Anime fans familiar with other titles will notice that this ranking is heavily weighted toward more recent titles -- our dataset goes back to 2007, but Frieren premiered in 2023, Spy x Family in 2022, and multiple other series listed are from 2024. Have late-night anime become more common on these rankings than they used to be, then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2007     6\n",
       "2008     8\n",
       "2009     9\n",
       "2010     5\n",
       "2011     4\n",
       "2012     4\n",
       "2013     4\n",
       "2014     3\n",
       "2015     7\n",
       "2016     6\n",
       "2017     2\n",
       "2018     4\n",
       "2019     5\n",
       "2020     6\n",
       "2021    34\n",
       "2022    40\n",
       "2023    51\n",
       "2024    73\n",
       "2025     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[late_night, 'Date'].dt.year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed they have, dramatically so. In the late 2000s, late-night shows in the top 10 anime broadcasts were a rarity, and mostly restricted to Fuji TV's relatively prestigious [noitaminA](https://en.wikipedia.org/wiki/Noitamina) block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>Noitamina - Nodame Cantabile</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-05-24</td>\n",
       "      <td>2007-04-30</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>You're Under Arrest: Full Throttle</td>\n",
       "      <td>TBS</td>\n",
       "      <td>2007-10-04</td>\n",
       "      <td>01:55</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-11-30</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>Noitamina: Moyashimon</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2007-10-11</td>\n",
       "      <td>00:35</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-11-30</td>\n",
       "      <td>2007-10-08</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9235</th>\n",
       "      <td>Noitamina: Moyashimon</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2007-10-18</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.3</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-11-30</td>\n",
       "      <td>2007-10-15</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9161</th>\n",
       "      <td>Noitamina: Moyashimon [Tales of Agriculture]</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2007-12-06</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-12-14</td>\n",
       "      <td>2007-12-03</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>Noitamina: Moyashimon [Tales of Agriculture] (...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2007-12-20</td>\n",
       "      <td>01:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2007-12-30</td>\n",
       "      <td>2007-12-17</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9121</th>\n",
       "      <td>Noitamina: Hakaba Kitarō</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-01-10</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-01-22</td>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>Noitamina: Library War</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-06-05</td>\n",
       "      <td>00:55</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-06-15</td>\n",
       "      <td>2008-06-02</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8815</th>\n",
       "      <td>Friday Special Roadshow Lupin III Special: Swe...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>21:03</td>\n",
       "      <td>111 min.</td>\n",
       "      <td>14.4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2008-08-05</td>\n",
       "      <td>2008-07-21</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8777</th>\n",
       "      <td>Friday Special Roadshow Death Note Rewrite 2: ...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2008-08-22</td>\n",
       "      <td>21:03</td>\n",
       "      <td>111 min.</td>\n",
       "      <td>11.8</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8744</th>\n",
       "      <td>Noitamina: Seiyō Kottō Yōgashiten ~Antique~ (f...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-09-18</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-09-29</td>\n",
       "      <td>2008-09-15</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>Noitamina: Nodame Cantabile: Paris</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-10-09</td>\n",
       "      <td>00:50</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-10-19</td>\n",
       "      <td>2008-10-06</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>Noitamina: Nodame Cantabile: Paris</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-11-20</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-11-30</td>\n",
       "      <td>2008-11-17</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8628</th>\n",
       "      <td>Noitamina: Nodame Cantabile: Paris</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2008-12-14</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>Noitamina: Genji Monogatari Sennenki: Genji</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-03-19</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2009-03-29</td>\n",
       "      <td>2009-03-16</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>NTV 55/YTV 50 Friday Special Roadshow: Lupin I...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2009-03-27</td>\n",
       "      <td>21:00</td>\n",
       "      <td>129 min.</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>2009-03-23</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8449</th>\n",
       "      <td>Noitamina: Eden of the East</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-04-09</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2009-04-16</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8389</th>\n",
       "      <td>Noitamina: Eden of the East</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-05-21</td>\n",
       "      <td>00:45</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2009-06-21</td>\n",
       "      <td>2009-05-18</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>Noitamina: Tokyo Magnitude 8.0</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-07-09</td>\n",
       "      <td>01:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2009-07-15</td>\n",
       "      <td>2009-07-06</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>Saturday Premium Fuji TV's 50th Anniversary/80...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2009-09-05</td>\n",
       "      <td>21:00</td>\n",
       "      <td>130 min.</td>\n",
       "      <td>13.1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2009-09-14</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  Station       Date  \\\n",
       "9312                       Noitamina - Nodame Cantabile  Fuji TV 2007-05-03   \n",
       "9255                 You're Under Arrest: Full Throttle      TBS 2007-10-04   \n",
       "9243                              Noitamina: Moyashimon  Fuji TV 2007-10-11   \n",
       "9235                              Noitamina: Moyashimon  Fuji TV 2007-10-18   \n",
       "9161       Noitamina: Moyashimon [Tales of Agriculture]  Fuji TV 2007-12-06   \n",
       "9141  Noitamina: Moyashimon [Tales of Agriculture] (...  Fuji TV 2007-12-20   \n",
       "9121                           Noitamina: Hakaba Kitarō  Fuji TV 2008-01-10   \n",
       "8895                             Noitamina: Library War  Fuji TV 2008-06-05   \n",
       "8815  Friday Special Roadshow Lupin III Special: Swe...      NTV 2008-07-25   \n",
       "8777  Friday Special Roadshow Death Note Rewrite 2: ...      NTV 2008-08-22   \n",
       "8744  Noitamina: Seiyō Kottō Yōgashiten ~Antique~ (f...  Fuji TV 2008-09-18   \n",
       "8709                 Noitamina: Nodame Cantabile: Paris  Fuji TV 2008-10-09   \n",
       "8650                 Noitamina: Nodame Cantabile: Paris  Fuji TV 2008-11-20   \n",
       "8628                 Noitamina: Nodame Cantabile: Paris  Fuji TV 2008-12-04   \n",
       "8479        Noitamina: Genji Monogatari Sennenki: Genji  Fuji TV 2009-03-19   \n",
       "8460  NTV 55/YTV 50 Friday Special Roadshow: Lupin I...      NTV 2009-03-27   \n",
       "8449                        Noitamina: Eden of the East  Fuji TV 2009-04-09   \n",
       "8389                        Noitamina: Eden of the East  Fuji TV 2009-05-21   \n",
       "8328                     Noitamina: Tokyo Magnitude 8.0  Fuji TV 2009-07-09   \n",
       "8241  Saturday Premium Fuji TV's 50th Anniversary/80...  Fuji TV 2009-09-05   \n",
       "\n",
       "       Time    Length  Average Household Rating Listed day of week  \\\n",
       "9312  00:45   30 min.                       5.1                Thu   \n",
       "9255  01:55   30 min.                       4.0                Thu   \n",
       "9243  00:35   30 min.                       4.9                Thu   \n",
       "9235  00:45   30 min.                       5.3                Thu   \n",
       "9161  00:45   30 min.                       4.9                Thu   \n",
       "9141  01:00   30 min.                       5.2                Thu   \n",
       "9121  00:45   30 min.                       4.8                Thu   \n",
       "8895  00:55   30 min.                       4.5                Thu   \n",
       "8815  21:03  111 min.                      14.4                Fri   \n",
       "8777  21:03  111 min.                      11.8                Fri   \n",
       "8744  00:45   30 min.                       4.5                Thu   \n",
       "8709  00:50   30 min.                       4.9                Thu   \n",
       "8650  00:45   30 min.                       5.0                Thu   \n",
       "8628  00:45   30 min.                       6.6                Thu   \n",
       "8479  00:45   30 min.                       4.2                Thu   \n",
       "8460  21:00  129 min.                      19.5                Fri   \n",
       "8449  00:45   30 min.                       4.8                Thu   \n",
       "8389  00:45   30 min.                       5.0                Thu   \n",
       "8328  01:00   30 min.                       5.8                Thu   \n",
       "8241  21:00  130 min.                      13.1                Sat   \n",
       "\n",
       "     Publish date First day of week Computed day of week  \n",
       "9312   2007-05-24        2007-04-30                  Thu  \n",
       "9255   2007-11-30        2007-10-01                  Thu  \n",
       "9243   2007-11-30        2007-10-08                  Thu  \n",
       "9235   2007-11-30        2007-10-15                  Thu  \n",
       "9161   2007-12-14        2007-12-03                  Thu  \n",
       "9141   2007-12-30        2007-12-17                  Thu  \n",
       "9121   2008-01-22        2008-01-07                  Thu  \n",
       "8895   2008-06-15        2008-06-02                  Thu  \n",
       "8815   2008-08-05        2008-07-21                  Fri  \n",
       "8777   2008-09-02        2008-08-18                  Fri  \n",
       "8744   2008-09-29        2008-09-15                  Thu  \n",
       "8709   2008-10-19        2008-10-06                  Thu  \n",
       "8650   2008-11-30        2008-11-17                  Thu  \n",
       "8628   2008-12-14        2008-12-01                  Thu  \n",
       "8479   2009-03-29        2009-03-16                  Thu  \n",
       "8460   2009-04-06        2009-03-23                  Fri  \n",
       "8449   2009-04-16        2009-04-06                  Thu  \n",
       "8389   2009-06-21        2009-05-18                  Thu  \n",
       "8328   2009-07-15        2009-07-06                  Thu  \n",
       "8241   2009-09-14        2009-08-31                  Sat  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[late_night].sort_values(by='Date').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reader may be curious to know what programs appear most often in these rankings, if most (but by no means all) of the ones best-known internationally are absent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Chibi Maruko-chan                               844\n",
       "One Piece                                       843\n",
       "Sazae-san                                       839\n",
       "Detective Conan                                 805\n",
       "Doraemon                                        661\n",
       "Crayon Shin-chan                                630\n",
       "Animated O-saru no George (Curious George)      383\n",
       "Oshiri Tantei                                   242\n",
       "Toriko                                          139\n",
       "Dragon Ball Super                               128\n",
       "Animation Hitsuji no Shaun (Shaun the Sheep)    105\n",
       "Pocket Monsters: Diamond & Pearl                 98\n",
       "GeGeGe no Kitarō                                 96\n",
       "Soreike! Anpanman                                95\n",
       "Dragon Ball Kai                                  95\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['Title'].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we must keep in mind that Pretty Cure changes its title annually; if all series were represented under a single title, they would be fifth in this ranking. Pokémon faces a similar issue, having aired under several different titles, though it doesn't change as often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pokémon entries: 448\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Pokémon entries: {}\".format(\n",
    "    cleaned_df['Title'].str.contains(r\"Pocket Mon|Pokémon\", regex=True).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most weeks, the highest-rated anime is Sazae-san, a sitcom that holds the Guinness World Record for the longest-running animated television series, having aired since 1969. In a typical year, it airs a new episode almost every week, with exceptions for holidays. The series has never been released internationally, nor has it ever been released on home video due to the original creator's wishes.\n",
    "\n",
    "It is very rare for a new episode of Sazae-san to air, but *not* be the highest-rated anime. So rare, in fact, that the instances in our dataset can all be listed individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Average Household Rating</th>\n",
       "      <th>Listed day of week</th>\n",
       "      <th>Publish date</th>\n",
       "      <th>First day of week</th>\n",
       "      <th>Computed day of week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8460</th>\n",
       "      <td>NTV 55/YTV 50 Friday Special Roadshow: Lupin I...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2009-03-27</td>\n",
       "      <td>21:00</td>\n",
       "      <td>129 min.</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>2009-03-23</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6660</th>\n",
       "      <td>One Piece Episode of Nami: Kōkaishi no Namida ...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2012-08-25</td>\n",
       "      <td>21:00</td>\n",
       "      <td>130 min.</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2012-09-02</td>\n",
       "      <td>2012-08-20</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592</th>\n",
       "      <td>One Piece \"3D2Y\" Ace no Shi wo Koete! Luffy Na...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2014-08-30</td>\n",
       "      <td>21:00</td>\n",
       "      <td>130 min.</td>\n",
       "      <td>12.2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>Crayon Shin-chan</td>\n",
       "      <td>TV Asahi</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>19:30</td>\n",
       "      <td>24 min.</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2020-08-22</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>Kinyō Road Show! Meitantei Conan Episode ONE C...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>21:00</td>\n",
       "      <td>114 min.</td>\n",
       "      <td>10.4</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>Kinyō Road Show! Meitantei Conan: Edogawa Cona...</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>21:00</td>\n",
       "      <td>114 min.</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Fri</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba: Bonds of Siblings</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>21:00</td>\n",
       "      <td>130 min.</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Kimetsu no Yaiba: Natagumoyama-hen</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>21:00</td>\n",
       "      <td>170 min.</td>\n",
       "      <td>15.4</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba: Hashira Gō Kai...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2020-12-20</td>\n",
       "      <td>18:59</td>\n",
       "      <td>135 min.</td>\n",
       "      <td>14.4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba - Asakusa Arc</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>19:00</td>\n",
       "      <td>135 min.</td>\n",
       "      <td>13.4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba - Mt. Natagumo Arc</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2021-09-19</td>\n",
       "      <td>19:00</td>\n",
       "      <td>174 min.</td>\n",
       "      <td>14.7</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba - The Hashira M...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2021-09-23</td>\n",
       "      <td>19:00</td>\n",
       "      <td>140 min.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2021-10-02</td>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>Thu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Mugen Train Arc</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2021-10-10</td>\n",
       "      <td>23:15</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2021-10-16</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>17:30</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Entertainment D...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>21:00</td>\n",
       "      <td>150 min.</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>2023-03-27</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Entertainment D...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2023-04-08</td>\n",
       "      <td>21:00</td>\n",
       "      <td>160 min.</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>23:15</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2023-05-27</td>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2023-06-11</td>\n",
       "      <td>23:15</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2023-06-17</td>\n",
       "      <td>2023-06-05</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2023-06-18</td>\n",
       "      <td>23:15</td>\n",
       "      <td>70 min.</td>\n",
       "      <td>7.6</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2023-06-24</td>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Doyō Premium Tokubetsu Henshū-ban Kimetsu no Y...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2024-02-17</td>\n",
       "      <td>21:00</td>\n",
       "      <td>150 min.</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2024-02-24</td>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>19:00</td>\n",
       "      <td>193 min.</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2024-05-11</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba Hashira Trainin...</td>\n",
       "      <td>Fuji TV</td>\n",
       "      <td>2024-06-16</td>\n",
       "      <td>23:15</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2024-06-22</td>\n",
       "      <td>2024-06-10</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Detective Conan</td>\n",
       "      <td>NTV</td>\n",
       "      <td>2024-11-02</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30 min.</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Sat</td>\n",
       "      <td>2024-11-09</td>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title   Station       Date  \\\n",
       "8460  NTV 55/YTV 50 Friday Special Roadshow: Lupin I...       NTV 2009-03-27   \n",
       "6660  One Piece Episode of Nami: Kōkaishi no Namida ...   Fuji TV 2012-08-25   \n",
       "5592  One Piece \"3D2Y\" Ace no Shi wo Koete! Luffy Na...   Fuji TV 2014-08-30   \n",
       "4697                                   Crayon Shin-chan  TV Asahi 2016-05-20   \n",
       "2431                                    Detective Conan       NTV 2020-08-22   \n",
       "2400  Kinyō Road Show! Meitantei Conan Episode ONE C...       NTV 2020-09-11   \n",
       "2390  Kinyō Road Show! Meitantei Conan: Edogawa Cona...       NTV 2020-09-18   \n",
       "2360  Demon Slayer: Kimetsu no Yaiba: Bonds of Siblings   Fuji TV 2020-10-10   \n",
       "2350                 Kimetsu no Yaiba: Natagumoyama-hen   Fuji TV 2020-10-17   \n",
       "2259  Demon Slayer: Kimetsu no Yaiba: Hashira Gō Kai...   Fuji TV 2020-12-20   \n",
       "1864       Demon Slayer: Kimetsu no Yaiba - Asakusa Arc   Fuji TV 2021-09-12   \n",
       "1854  Demon Slayer: Kimetsu no Yaiba - Mt. Natagumo Arc   Fuji TV 2021-09-19   \n",
       "1844  Demon Slayer: Kimetsu no Yaiba - The Hashira M...   Fuji TV 2021-09-23   \n",
       "1823     Demon Slayer: Kimetsu no Yaiba Mugen Train Arc   Fuji TV 2021-10-10   \n",
       "1344                                    Detective Conan       NTV 2022-08-27   \n",
       "1021  Demon Slayer: Kimetsu no Yaiba Entertainment D...   Fuji TV 2023-04-01   \n",
       "1011  Demon Slayer: Kimetsu no Yaiba Entertainment D...   Fuji TV 2023-04-08   \n",
       "943   Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...   Fuji TV 2023-05-21   \n",
       "911   Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...   Fuji TV 2023-06-11   \n",
       "901   Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...   Fuji TV 2023-06-18   \n",
       "583                                     Detective Conan       NTV 2024-01-06   \n",
       "522   Doyō Premium Tokubetsu Henshū-ban Kimetsu no Y...   Fuji TV 2024-02-17   \n",
       "410   Demon Slayer: Kimetsu no Yaiba Swordsmith Vill...   Fuji TV 2024-05-05   \n",
       "348   Demon Slayer: Kimetsu no Yaiba Hashira Trainin...   Fuji TV 2024-06-16   \n",
       "136                                     Detective Conan       NTV 2024-11-02   \n",
       "\n",
       "       Time    Length  Average Household Rating Listed day of week  \\\n",
       "8460  21:00  129 min.                      19.5                Fri   \n",
       "6660  21:00  130 min.                      11.6                Sat   \n",
       "5592  21:00  130 min.                      12.2                Sat   \n",
       "4697  19:30   24 min.                       8.3                Fri   \n",
       "2431  17:30   30 min.                       7.9                Sat   \n",
       "2400  21:00  114 min.                      10.4                Fri   \n",
       "2390  21:00  114 min.                      10.5                Fri   \n",
       "2360  21:00  130 min.                      16.7                Sat   \n",
       "2350  21:00  170 min.                      15.4                Sat   \n",
       "2259  18:59  135 min.                      14.4                Sun   \n",
       "1864  19:00  135 min.                      13.4                Sun   \n",
       "1854  19:00  174 min.                      14.7                Sun   \n",
       "1844  19:00  140 min.                      15.0                Thu   \n",
       "1823  23:15   30 min.                      10.0                Sun   \n",
       "1344  17:30   30 min.                       6.9                Sat   \n",
       "1021  21:00  150 min.                       8.3                Sat   \n",
       "1011  21:00  160 min.                       9.1                Sat   \n",
       "943   23:15   30 min.                       7.0                Sun   \n",
       "911   23:15   30 min.                       7.6                Sun   \n",
       "901   23:15   70 min.                       7.6                Sun   \n",
       "583   18:00   30 min.                       6.7                Sat   \n",
       "522   21:00  150 min.                       7.5                Sun   \n",
       "410   19:00  193 min.                       8.1                Sun   \n",
       "348   23:15   30 min.                       6.4                Sun   \n",
       "136   18:00   30 min.                       6.8                Sat   \n",
       "\n",
       "     Publish date First day of week Computed day of week  \n",
       "8460   2009-04-06        2009-03-23                  Fri  \n",
       "6660   2012-09-02        2012-08-20                  Sat  \n",
       "5592   2014-09-08        2014-08-25                  Sat  \n",
       "4697   2016-05-26        2016-05-16                  Fri  \n",
       "2431   2020-08-28        2020-08-17                  Sat  \n",
       "2400   2020-09-18        2020-09-07                  Fri  \n",
       "2390   2020-09-28        2020-09-14                  Fri  \n",
       "2360   2020-10-16        2020-10-05                  Sat  \n",
       "2350   2020-10-23        2020-10-12                  Sat  \n",
       "2259   2020-12-25        2020-12-14                  Sun  \n",
       "1864   2021-09-18        2021-09-06                  Sun  \n",
       "1854   2021-09-27        2021-09-13                  Sun  \n",
       "1844   2021-10-02        2021-09-20                  Thu  \n",
       "1823   2021-10-16        2021-10-04                  Sun  \n",
       "1344   2022-09-03        2022-08-22                  Sat  \n",
       "1021   2023-04-08        2023-03-27                  Sat  \n",
       "1011   2023-04-15        2023-04-03                  Sat  \n",
       "943    2023-05-27        2023-05-15                  Sun  \n",
       "911    2023-06-17        2023-06-05                  Sun  \n",
       "901    2023-06-24        2023-06-12                  Sun  \n",
       "583    2024-01-20        2024-01-01                  Sat  \n",
       "522    2024-02-24        2024-02-12                  Sat  \n",
       "410    2024-05-11        2024-04-29                  Sun  \n",
       "348    2024-06-22        2024-06-10                  Sun  \n",
       "136    2024-11-09        2024-10-28                  Sat  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def by_week(df: pd.DataFrame):\n",
    "    return df.groupby('First day of week')\n",
    "\n",
    "def sazae_san_dethroned(week_df: pd.DataFrame):\n",
    "    if (~week_df['Title'].str.contains('Sazae')).all():\n",
    "        return False # No Sazae-san episode this week.\n",
    "    if \"Sazae\" in week_df.loc[\n",
    "        week_df['Average Household Rating'].idxmax(),\n",
    "        'Title'\n",
    "    ]:\n",
    "        return False # Sazae-san was the top show.\n",
    "    return True\n",
    "\n",
    "sazae_dethroned_weeks = by_week(cleaned_df).filter(sazae_san_dethroned)\n",
    "conquerers = by_week(sazae_dethroned_weeks)['Average Household Rating'].idxmax()\n",
    "cleaned_df.loc[conquerers].sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first broadcasts listed are all specials over two hours long. A 2016 broadcast of Crayon Shin-chan was the first regular anime broadcast to outperform Sazae-san since at least 2007, and the next time after that wasn't until 2020. It is a testament to the colossal popularity of Demon Slayer that it has achieved this feat as many times as it has in a four-year span, including with regular episodes airing after 11:00 PM.\n",
    "\n",
    "The reader may notice, however, that dethroning Sazae-san doesn't take quite the numbers it used to, as shown by the `Average Household Rating` column. Indeed, Sazae-san's average ratings have declined considerably:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2007-01-01    18.317391\n",
       "2008-01-01    17.910000\n",
       "2009-01-01    18.161702\n",
       "2010-01-01    19.958696\n",
       "2011-01-01    19.185714\n",
       "2012-01-01    17.752083\n",
       "2013-01-01    16.810417\n",
       "2014-01-01    15.842000\n",
       "2015-01-01    13.931250\n",
       "2016-01-01    12.097959\n",
       "2017-01-01    11.908511\n",
       "2018-01-01    11.954167\n",
       "2019-01-01    12.094118\n",
       "2020-01-01    10.090196\n",
       "2021-01-01     9.336000\n",
       "2022-01-01     8.518750\n",
       "2023-01-01     7.880000\n",
       "2024-01-01     7.440000\n",
       "2025-01-01     8.275000\n",
       "Freq: YS-JAN, Name: Average Household Rating, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.loc[\n",
    "    cleaned_df['Title'].str.contains('Sazae')\n",
    "].groupby(pd.Grouper(key='Date', freq='YS'))['Average Household Rating'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It still usually tops the charts, of course, because the phenomenon is far from unique to Sazae-san. As in most countries, live TV viewership has declined over time in Japan, as people move to time-shifting, streaming, and other forms of entertainment altogether. We can see this trend more broadly in the anime charts by looking at what numbers are required to break into the *bottom* of the chart on the average week of each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First day of week\n",
       "2007-01-01    4.996000\n",
       "2008-01-01    5.242308\n",
       "2009-01-01    5.113725\n",
       "2010-01-01    5.173077\n",
       "2011-01-01    4.551923\n",
       "2012-01-01    4.220755\n",
       "2013-01-01    4.086538\n",
       "2014-01-01    4.480769\n",
       "2015-01-01    3.870588\n",
       "2016-01-01    3.305769\n",
       "2017-01-01    3.221154\n",
       "2018-01-01    2.903774\n",
       "2019-01-01    2.834615\n",
       "2020-01-01    2.800000\n",
       "2021-01-01    2.478846\n",
       "2022-01-01    2.144231\n",
       "2023-01-01    1.861538\n",
       "2024-01-01    1.807547\n",
       "2025-01-01    1.775000\n",
       "Freq: YS-JAN, Name: Average Household Rating, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_ratings = by_week(cleaned_df)['Average Household Rating'].min()\n",
    "bottom_ratings.groupby(pd.Grouper(freq='YS')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at another long-running series like One Piece:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Episodes charted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.795238</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>7.859574</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>9.914583</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.475510</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.083673</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>7.993750</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.122000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015</td>\n",
       "      <td>8.436170</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>7.854348</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>6.514894</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>5.523404</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>5.187755</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020</td>\n",
       "      <td>4.420000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>3.476000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023</td>\n",
       "      <td>3.345833</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024</td>\n",
       "      <td>2.838298</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Average rating  Episodes charted\n",
       "0   2007        8.795238                21\n",
       "1   2008        7.859574                47\n",
       "2   2009        9.914583                48\n",
       "3   2010       11.475510                49\n",
       "4   2011       10.166667                48\n",
       "5   2012        9.083673                49\n",
       "6   2013        7.993750                48\n",
       "7   2014        8.122000                50\n",
       "8   2015        8.436170                47\n",
       "9   2016        7.854348                46\n",
       "10  2017        6.514894                47\n",
       "11  2018        5.523404                47\n",
       "12  2019        5.187755                49\n",
       "13  2020        4.420000                50\n",
       "14  2021        4.057143                49\n",
       "15  2022        3.476000                50\n",
       "16  2023        3.345833                48\n",
       "17  2024        2.838298                47\n",
       "18  2025        2.500000                 3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_rating_by_year(exact_title: str):\n",
    "    by_year = cleaned_df.loc[\n",
    "        cleaned_df['Title'] == exact_title\n",
    "    ].groupby(pd.Grouper(key='Date', freq='YS'))\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        'Average rating': by_year['Average Household Rating'].mean(),\n",
    "        'Episodes charted': by_year.size(),\n",
    "    }).reset_index()\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'Year': summary['Date'].dt.year,\n",
    "        'Average rating': summary['Average rating'],\n",
    "        'Episodes charted': summary['Episodes charted'],\n",
    "    })\n",
    "\n",
    "avg_rating_by_year(\"One Piece\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, with a little more work, comparing each Pretty Cure series, which I'll label with the year it started in (generally in February)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Average rating</th>\n",
       "      <th>Episodes charted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes! Precure 5</td>\n",
       "      <td>2007</td>\n",
       "      <td>6.516000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes! Precure 5 GoGo!</td>\n",
       "      <td>2008</td>\n",
       "      <td>5.772973</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fresh Precure!</td>\n",
       "      <td>2009</td>\n",
       "      <td>6.553191</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heartcatch Precure!</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.637778</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suite Precure</td>\n",
       "      <td>2011</td>\n",
       "      <td>5.276190</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smile Precure!</td>\n",
       "      <td>2012</td>\n",
       "      <td>5.354348</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dokidoki! Precure</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.927273</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HappinessCharge PreCure!</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.854839</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Go! Princess Precure</td>\n",
       "      <td>2015</td>\n",
       "      <td>4.255882</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mahō Tsukai Precure!</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.637500</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kirakira ☆ Precure a la Mode</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.496296</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hugtto! Precure</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Star ☆ Twinkle Precure</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.561364</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Healin' Good Precure</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.185366</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tropical-Rouge! Precure</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.937778</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delicious Party♡Precure</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.968085</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Soaring Sky! Pretty Cure</td>\n",
       "      <td>2023</td>\n",
       "      <td>2.966000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wonderful Precure!</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.767347</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>You and Idol Precure♪</td>\n",
       "      <td>2025</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title  Year  Average rating  Episodes charted\n",
       "0                 Yes! Precure 5  2007        6.516000                25\n",
       "1           Yes! Precure 5 GoGo!  2008        5.772973                37\n",
       "2                 Fresh Precure!  2009        6.553191                47\n",
       "3            Heartcatch Precure!  2010        6.637778                45\n",
       "4                  Suite Precure  2011        5.276190                42\n",
       "5                 Smile Precure!  2012        5.354348                46\n",
       "6              Dokidoki! Precure  2013        4.927273                44\n",
       "7       HappinessCharge PreCure!  2014        4.854839                31\n",
       "8           Go! Princess Precure  2015        4.255882                34\n",
       "9           Mahō Tsukai Precure!  2016        3.637500                24\n",
       "10  Kirakira ☆ Precure a la Mode  2017        3.496296                27\n",
       "11               Hugtto! Precure  2018        3.520000                45\n",
       "12        Star ☆ Twinkle Precure  2019        3.561364                44\n",
       "13          Healin' Good Precure  2020        3.185366                41\n",
       "14       Tropical-Rouge! Precure  2021        2.937778                45\n",
       "15       Delicious Party♡Precure  2022        2.968085                47\n",
       "16      Soaring Sky! Pretty Cure  2023        2.966000                50\n",
       "17            Wonderful Precure!  2024        2.767347                49\n",
       "18         You and Idol Precure♪  2025        3.300000                 1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_precure_titles(t: pd.Series):\n",
    "    # Remove parenthetical notes like (first episode) and (final episode)\n",
    "    t = t.str.replace(r\" \\(.*?\\)$\", '', regex=True)\n",
    "\n",
    "    # Two cases where such notes appear without parentheses\n",
    "    t = t.str.replace(r\" Fi\\w+ Episode$\", '', regex=True)\n",
    "\n",
    "    # Spelling of \"Precure\" wasn't standardized at first\n",
    "    t = t.str.replace(r\"Pre-Cure\", 'Precure', regex=True)\n",
    "    return t\n",
    "\n",
    "# Omit six reruns from when production was delayed due to COVID-19.\n",
    "# These are listed as \"Healin' Good Precure Osarai Selection\".\n",
    "precure_rows = cleaned_df.loc[\n",
    "    cleaned_df['Title'].str.contains(r\"Pre.+ure\")\n",
    "    & ~cleaned_df['Title'].str.endswith(\"Osarai Selection\")\n",
    "].copy()\n",
    "\n",
    "precure_rows['Title'] = normalize_precure_titles(precure_rows['Title'])\n",
    "precure_by_title = precure_rows.groupby('Title')\n",
    "pd.DataFrame({\n",
    "    'Year': precure_by_title['Date'].min().dt.year,\n",
    "    'Average rating': precure_by_title['Average Household Rating'].mean(),\n",
    "    'Episodes charted': precure_by_title.size(),\n",
    "}).sort_values(by='Year').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be related to the phenomenon of late-night anime making the charts more often; they could be more resistant to the trends that have driven viewership down. It's likely not the only cause, however -- the wild success of Demon Slayer makes it clear that late-night anime is simply far more mainstream than it once was. The likes of Spy x Family and Jujutsu Kaisen have regularly ranked among Japan's best-selling manga, and were recognized early on as potential major hits, yet their anime adaptations aired late at night, and to great success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this has proven of interest, and that it will lead to further research -- as well as improved fan understanding of the works they love, and the systems that produce them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_broadcast_ratings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
